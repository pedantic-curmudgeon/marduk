version: "3.9"
services:
    # Start test database.
    db:
        image: "mariadb:latest"
        container_name: "db_container"
        ports:
            # This maps port host port 3306 to the container port 3306.
            # That way, we can connect to the database from outside
            # of the Docker network (i.e. the local machine). :)
            - "3306:3306"
        restart: "on-failure"
        environment:
            MYSQL_DATABASE: "${DB_NAME}"
            MYSQL_ROOT_PASSWORD: "${DB_PASSWORD}"
    # Run Liquibase change log against test database.
    liquibase:
        image: "liquibase/liquibase:latest"
        container_name: "liquibase_container"
        restart: "on-failure"
        depends_on:
            - "db"
        volumes:
            - "/home/raeganbarker/.pyenv/versions/3.8.2/lib/python3.8/site-packages/$REPO_NAME/docker-compose:/liquibase/changelog"
            - "data_volume:/liquibase"
        entrypoint: ["/bin/sh","-c"]
        # Wait for Liquibase migration to complete.
        command:
        - |
            until liquibase \
                --url="jdbc:mariadb://db_container:3306/${DB_NAME}" \
                --username="${DB_USER}" \
                --password="${DB_PASSWORD}" \
                --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" \
                update; \
                do sleep 5; \
                done
            touch liquibase.complete
            ls -la
            pwd
            exit
    repo:
        image: "raeganbarker/$REPO_NAME:$TAG"
        container_name: "repo_container"
        restart: "on-failure"
        depends_on:
            - "liquibase"
        volumes:
            - "data_volume:/app/$REPO_NAME/bkp"
        entrypoint: ["/bin/sh","-c"]
        command:
        - |
            until [ -f /app/$REPO_NAME/bkp/liquibase.complete ]; \
                do echo "Waiting for Liquibase to complete...";
                ls -la;
                sleep 5; \
                done
            python3 /app/$REPO_NAME/pytests/runner.py


volumes:
    data_volume:

# TODO: Create a placeholder docker_volume directory for the data volume in the dockerfile /app/docker_volume
# TODO: Obtain the liquibase changelog


# docker compose up
# docker compose down --volumes

        # pwd \
        # && \
        # ls -la \
        # && \
        # until [ -f /app/$REPO_NAME/liquibase.complete ]; \
        #     do echo "Waiting for Liquibase to complete...";
        #     ls -la;
        #     sleep 5; \
        #     done \
        # && \
        # pwd \
        # && \
        # cd pytests
        # && \
        # ls -la \
        # && \
        # exit


        # pwd \
        # && \
        # python3 /app/$REPO_NAME/pytests/runner.py \
        # && \
        # exit


        # until [ -f /app/$REPO_NAME/liquibase.complete ]; \
        # do echo "Waiting for Liquibase to complete...";
        # ls -la;
        # sleep 5; \
        # done

# TODO: Add content repo. Map to volume. Use conditional execution of tests. Make sure the container stops!

        # # content
        # entrypoint: ["/bin/sh","-c"]
        # command:
        # - |
        #     while [ ! -f /app/$REPO_NAME/liquibase.complete ]; \
        #         do sleep 5; \
        #         done
        #     python3 /app/$REPO_NAME/pytests/runner.py
        # exit?


# while [ ! -f 1.txt ]; do echo "Waiting for file..."; sleep 5; done


# works:
# until liquibase --url="jdbc:mariadb://db_container:3306/${DB_NAME}" --username="${DB_USER}" --password="${DB_PASSWORD}" --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" update; do sleep 5; done
# touch migration_comple.txt
# pwd
# ls -la


# while [ ! -f 0.txt ]; do liquibase --url="jdbc:mariadb://db_container:3306/${DB_NAME}" --username="${DB_USER}" --password="${DB_PASSWORD}" --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" update; touch `$$?`.txt; echo "Waiting for Liquibase to succeed"; ls -la; sleep 5 ; done
# touch complete.txt

    # liquibase --url="jdbc:mariadb://db_container:3306/${DB_NAME}" --username="${DB_USER}" --password="${DB_PASSWORD}" --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" update
    # touch `echo $$?`.txt
    # ls -la
    # pwd

    # while [ `docker inspect --format '{{json .State.Running}}' repo_container` = "true" ]; do echo "Waiting for repo_container to exit..."; docker ps; sleep 5; done


# sh -c "liquibase --url="jdbc:mariadb://db_container:3306/${DB_NAME}" \
#         --username="${DB_USER}" --password="${DB_PASSWORD}" \
#         --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" update \
#         && touch `echo $$?`.txt && pwd"

# liquibase --url="jdbc:mariadb://db_container:3306/${DB_NAME}" --username="${DB_USER}" --password="${DB_PASSWORD}" --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" update

# liquibase --url="jdbc:mariadb://db_container:3306/${DB_NAME}" \
# --username="${DB_USER}" --password="${DB_PASSWORD}" \
# --changeLogFile="/changelog/liquibase_changelog_mysql_mariadb.sql" update \
# && touch `echo $$?`.txt && pwd


# networks:
#     default

    # Run repo tests on test database.
    # repo:
    #     build: .
    #     restart: always
    #     depends_on: liquibase


# https://docs.docker.com/compose/startup-order/
# repo docker image should include the test execution statement?
# need to map volumes so that we can get the test results from the repo?
# in a CI/CD world, we would build/push the repo image, and then reference
# it above instead of using 'build . ' , right?
# Mariadb always uses port 3306?

# This might be useful: https://github.com/ufoscout/docker-compose-wait
# It would need to go into any "waiting" image, though?

# https://docs.docker.com/compose/networking/
# When you compose up, the services will join the "myapp_default" network

# Environment variables:
# https://docs.docker.com/compose/environment-variables/


# Starting/Stopping
# docker-compose up -d
# docker-compose down --volumes

# Other options:
# 1. Make custom image for Liquibase which bundles the change log and wait for it?
# 2. Make custom image for database (Not needed?)
# 3. Make custom image of content which bundles wait for it?

# Still to figure out:
# What's the best way to get the liquibase change log files passed?
# What's the best way to get a content repo to work?
# Can we depend on an exit code from another service before starting another?
# - Doesn't look like it.

# Easiest approach is having the database image already ready.

# https://kifarunix.com/install-and-run-mariadb-as-a-docker-container/
# Keep the data in the Git repo where we define the container?
# Then, when we pull the image, we also have to pull the data?
# Can manually specify a different volume mount?
# $ docker run --name some-mariadb -v /my/own/datadir:/var/lib/mysql -e MARIADB_ROOT_PASSWORD=my-secret-pw -d mariadb:tag

# Progress:
# Starts database
# Tries to update with Liquibase and keeps trying until exit code 0 reached

# Next steps:
# Set up a test using a compose file instead of just a single docker image
# https://gist.github.com/cecilemuller/437d7340b9f095cf5635dc9780a05092
# https://stackoverflow.com/questions/61491484/how-to-cache-docker-compose-build-inside-github-action
# https://github.com/peter-evans/docker-compose-actions-workflow/blob/master/README.md
# https://github.com/docker/login-action
# It looks like the commands are just run on the GH VM for docker compose
# So, we need to log in first, I believe, since we're referencing private repos.
# But can just log in with this like in first example? https://github.com/docker/login-action
# Have multiple dockerfiles in same directory?
# With compose, can we just do a build . (Or whatever directory!)?
# And bypass publishing to DockerHub?
# Would like to just publish the production image to DockerHub on PR approval?
# Might still be good to build the image. For testing purposes.
# Need to specify a volume so the tests execute to it and can be retrieved from there?
# Can my volume just map /github/workspace:/app/$REPO_NAME/pytests?

# Where to get the test files from? https://github.community/t/how-can-i-access-the-current-repo-context-and-files-from-a-docker-container-action/17711/8
